{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171d9bec",
   "metadata": {},
   "source": [
    "<img src=\"lg.png\" style=\"width:90px; height:300px/\">\n",
    "\n",
    "**Team Name**:\n",
    "ICA \n",
    "\n",
    "**Submitted by**:\n",
    "<br /> Umesh Kumar Naik M\n",
    "<br /> Direct PhD Student\n",
    "<br /> Department of Electronics and Electrical Engineering\n",
    "<br /> Indian Institute of Technology Guwahati\n",
    "<br /> Guwahati, Assam 781039 \n",
    "<br /> Email: u.mudavath@iitg.ac.in\n",
    "\n",
    "**Submitted to**:\n",
    "<br /> Dr. Neeraj Kumar Sharma\n",
    "<br /> Assistant Professor\n",
    "<br /> Mehta Family School of Data Science and Artificial Intelligence\n",
    "<br /> Indian Institute of Technology Guwahati \n",
    "<br /> Guwahati, Assam 781039\n",
    "<br /> Email:  neerajs@iitg.ac.in\n",
    "\n",
    "---\n",
    "\n",
    "**Project Title**:\n",
    "Comparison of various Machine Learning and Deep Learning approaches for the Classification of Epileptic Seizures From EEG Signals        \n",
    "\n",
    "**Objective**:\n",
    "The objective of this work is to compare and evaluate the performance of various machine learning (ML) and deep learning (DL) approaches for the classification of epileptic seizures from EEG signals. The aim is to identify the most effective method for accurately and efficiently classifying epileptic seizures, which could have important applications in clinical settings for diagnosing and treating epilepsy.\n",
    "\n",
    "**Background**:\n",
    "<br /> Epilepsy is a neurological disorder that affects approximately 50 million people worldwide. It is characterized by recurrent seizures, which are abnormal electrical activities in the brain. Electroencephalogram (EEG) signals are commonly used for the diagnosis and monitoring of epilepsy. Machine learning and deep learning approaches have shown promising results in the classification of epileptic seizures from EEG signals. In this study, we aim to compare various machine learning and deep learning approaches for the classification of epileptic seizures from EEG signals. We will evaluate the performance of these approaches using various metrics such as accuracy, sensitivity, specificity, and area under the curve (AUC). This work is important as accurate classification of epileptic seizures can aid in the diagnosis and treatment of epilepsy.\n",
    "\n",
    "**Tools Used**:\n",
    "1. MATLAB R2021b\n",
    "2. Python + Colab\n",
    "\n",
    "**Contribution**:\n",
    "1. Preprocessing\n",
    "2. Feature engineering\n",
    "3. ML and DL model development \n",
    "\n",
    "**Database Description**:\n",
    "<br /> The dataset used in our work is taken from the publicly available database of department of epileptology from university of Bonn, Germany. The Dataset is comprised of five groups, namely A to E, each group contains 100 single-channel EEG signals, and each signal is of 23.6-sec in length with 4097 examples.\n",
    "\n",
    "**Methodology**:\n",
    "<br /> The methodology for this work involves the following steps:\n",
    "* Data acquisition: EEG signals from patients with epilepsy and control are collected using standard clinical procedures.\n",
    "* Preprocessing: The EEG signals are preprocessed and segmented into relevant frequency bands.\n",
    "* Feature extraction: Various features are extracted from the preprocessed EEG signals to represent the underlying dynamics of the brain activity.\n",
    "* Model selection: Several machine learning and deep learning models are evaluated for their performance in classifying epileptic seizures from EEG signals.\n",
    "* Training and testing: The selected models are trained on a subset of the data and tested on a separate validation set to evaluate their accuracy and generalization performance.\n",
    "* Performance evaluation: The performance of the models is evaluated using various metrics such as accuracy, sensitivity, specificity, F1 score, and AUC.\n",
    "* Comparison and analysis: The results of the different models are compared and analyzed to identify the most effective approach for classifying epileptic seizures from EEG signals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870fac5",
   "metadata": {},
   "source": [
    "**Workflow**<img src=\"wf.png\" style=\"width:250px; height:300px/\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205269b",
   "metadata": {},
   "source": [
    "_Mainly, the work is implemented in six different approaches:_\n",
    "* Data Acquisition  and Preprocessing\n",
    "1. Handcrafted features (Time Domain, Frequency Domain, and TFD)\n",
    "* Followed by classification using ML models\n",
    "2. Dimension reduced features + ML models\n",
    "* Dimensionality reduction of processed data Vs features using Principal component analysis (PCA)\n",
    "* Decomposition using discrete wavelet transform (DWT) and then\n",
    "3. Convolutional Autoencoder (latent space representation) + Random Forest (RF) classifier\n",
    "4. Denoising Autoencoder + Random Forest (RF) classifier\n",
    "5. 1D CNN (Robustness)\n",
    "* Only few samples are available (Then, Zero padding and Replicating)\n",
    "* With Synthetic Noise (EMG, EOG, line, motion, and environment noise artefacts)\n",
    "6. Scalogram based 2D CNN Vs Transfer Learning models (InceptionV3, VGG19, ResNet50 and EfficientNetB0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d427db",
   "metadata": {},
   "source": [
    "**Handcrafted features**:\n",
    "<br /> These features can be used to feed ML models for classification.\n",
    "1. Mean: The average value of a signal.\n",
    "2. Standard Deviation: The measure of the amount of variation or dispersion in a signal from the mean value.\n",
    "3. Minimum: The lowest value of a signal.\n",
    "4. Maximum: The highest value of a signal.\n",
    "5. Delta power: The power of the delta frequency band (0-4 Hz).\n",
    "6. Theta power: The power of the theta frequency band (4-8 Hz).\n",
    "7. Alpha power: The power of the alpha frequency band (8-12 Hz).\n",
    "8. Beta power: The power of the beta frequency band (12-30 Hz).\n",
    "9. Gamma power: The power of the gamma frequency band (30-100 Hz).\n",
    "10. Energy: The total energy in a signal.\n",
    "11. Dominant frequency: The frequency with the highest power in a signal.\n",
    "12. Shannon Entropy: The measure of the unpredictability or information content in a signal.\n",
    "13. Spike Rhythmicity: The measure of the rhythmicity of spikes in a signal.\n",
    "\n",
    "**Principal component analysis (PCA)**:\n",
    "<br /> PCA is a dimensionality reduction method that is often used to reduce the dimensionality of large data sets by transforming a large set of variables into a smaller one that still contains most of the information in the large set. It can be applied directly to the raw EEG data to extract latent variables that capture the most significant information (high variance) in the data (<u>Although it is not recommended to apply PCA directly to the data<u>). \n",
    "    \n",
    "Employing PCA on high-dimensional EEG data can help reduce the number of variables and reduce the training time of the ML model. However, handcrafted features extracted from EEG data are designed based on prior knowledge and domain expertise which are later fed to ML models for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a60fc1",
   "metadata": {},
   "source": [
    "**Performance metrics**:\n",
    "* Accuracy: measures the proportion of correct predictions among all predictions.\n",
    "* Precision: measures the proportion of true positives among all positive predictions.\n",
    "* Recall: measures the proportion of true positives among all actual positives.\n",
    "* F1-score: measures the harmonic mean of precision and recall, providing a single score that balances both measures.\n",
    "* Confusionmatrix: a table showing the true-positive, true-negative, false-positive, and false-negative predictions made by a classification model.\n",
    "* AUC curve: plots the true-positive rate (sensitivity) against the false-positive rate (1-specificity) for different classification thresholds, providing an overall measure of a model's performance.\n",
    "\n",
    "<img src=\"perq.png\" style=\"width:250px; height:500px/\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c068a050",
   "metadata": {},
   "source": [
    "**Classification directly on the data - BE** \n",
    "<img src=\"dir1.png\" style=\"width:650px; height:500px/\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c49bb65",
   "metadata": {},
   "source": [
    "**Correlation between features - AE** <img src=\"corr1.png\" style=\"width:300px; height:100px/\">\n",
    "\n",
    "**Classification on Handcrafted features - AE** \n",
    "<img src=\"hcf.png\" style=\"width:400px; height:100px/\">\n",
    "<img src=\"hc1.png\" style=\"width:600px; height:100px/\"> \n",
    "\n",
    "* AUC score before reduction: 0.9583\n",
    "* AUC score after reduction 6 PCs: 0.9333\n",
    "* AUC score after reduction 3 PCs: 0.9083 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d8c24",
   "metadata": {},
   "source": [
    "**Discrete wavelet transform (DWT)**:\n",
    "<br /> DWT is a suitable evaluation tool for non-stationary signals like EEG after the complete signal is represented in the matrix form. Here, the EEG signal is segmented into diverse frequency band signals employing WT. After processing, the signal is reconstructed by excluding the non-critical part of the signal. In our case, we decomposed the EEG signal to 5 levels. The block diagram below is for the analysis part. Similarly, we can have the synthesis part for reconstructing back the EEG signal exempting the undesired frequency bands.\n",
    "\n",
    "**Analysis part of DWT**\n",
    "<img src=\"dwt.png\" style=\"width:400px; height:100px/\"> \n",
    "\n",
    "**Convolutional Autoencoder (CAE)**:\n",
    "<br /> A convolutional autoencoder is a type of neural network that can be used for unsupervised learning of feature representations in data, and it is particularly well-suited for analyzing image or signal data such as EEG signals. The AE consists of two main parts: an encoder and a decoder. The encoder uses convolutional layers to extract features from the input data, and downsamples the feature map using max pooling or strided convolutions. The decoder then uses transposed convolutional layers to upsample the feature map and reconstruct the original input.\n",
    "\n",
    "The goal of the CAE is to learn a compressed representation of the input data that captures its most important features, while discarding the noise and other irrelevant information. \n",
    "\n",
    "**Denoising Autoencoder (DAE)**:\n",
    "<br /> A denoising autoencoder is a type of AE that is designed to remove noise from given input signal. The architecture of a denoising autoencoder is similar to that of a regular AE, but the input is corrupted with noise before being fed into the network. The model is then trained to reconstruct the original input from the noisy input.\n",
    "\n",
    "The idea behind the denoising autoencoder is that by training the network to reconstruct the original input from a corrupted version, it will learn to focus on the most important features of the data and ignore the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687df84b",
   "metadata": {},
   "source": [
    "**Convolutional Autoencoder Block diagram\n",
    "<img src=\"cc.png\" style=\"width:500px; height:100px/\"> \n",
    "Convolutional Autoencoder results for AE case**\n",
    "(Loss curve, original vs reconstructed EEG signal, confusion metrix and AUC plot for RF classifier)\n",
    "<img src=\"ca.png\" style=\"width:550px; height:100px/\"> \n",
    "\n",
    "**Denoising Autoencoder results for AE case** \n",
    "(Original vs reconstructed EEG signal, confusion metrix and AUC plot for RF classifier)\n",
    "<img src=\"da.png\" style=\"width:550px; height:100px/\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3edad2",
   "metadata": {},
   "source": [
    "**1D Convolutional neural network (CNN)**:\n",
    "<br />  A CNN is a type of deep neural network commonly used for image and video processing that can learn hierarchical representations of input data through the use of convolutional layers and pooling layers\n",
    "\n",
    "**1D CNN (Complete, Zero padding, replicate)** (Accuracy and Loss curve, confusion metrix, and AUC curve) <img src=\"om1.png\" style=\"width:600px; height:100px/\"> \n",
    "\n",
    "**1D CNN + Noise** (Accuracy and Loss curve, confusion metrix, and AUC curve) <img src=\"cnno.png\" style=\"width:500px; height:100px/\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c1e388",
   "metadata": {},
   "source": [
    "**Continuous wavelet transform (CWT)**:\n",
    "<br /> Scalograms computed using a CWT filter bank for EEG data provide a time-frequency representation of the signal. They are created by convolving the signal with a set of wavelets at different scales, resulting in a multi-resolution decomposition of the signal in both time and frequency domains. The resulting scalogram matrix shows the magnitude of the wavelet coefficients at each time and frequency point, allowing visualization of the signal's spectral characteristics over time. This technique can help identify transient features in the signal, such as event-related potentials, that may not be visible in the raw EEG data. Now, we would be giving these images to transfer learning models and DL model for classification.\n",
    "\n",
    "**Scalogram examples using CWT** <img src=\"sam.png\" style=\"width:550px; height:100px/\"> \n",
    "\n",
    "\n",
    "**Transfer Learning models**:\n",
    "<br /> Transfer learning models work well even with small data sizes. They are pre-trained on the large-scale ImageNet dataset, which consists of over 1 million labeled images from 1000 classes. ImageNet is a widely used benchmark for image classification tasks and includes a diverse range of object categories. This enables the model to generalize better and reduce overfitting, which is especially important when working with small datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51666bba",
   "metadata": {},
   "source": [
    "**Transfer Learning results for BE case with InceptionV3 vs 2D CNN** (Accuracy and Loss curve, confusion metrix)\n",
    "<img src=\"tl.png\" style=\"width:500px; height:100px/\"> \n",
    "\n",
    "**Comparission of all models for AE case**\n",
    "<img src=\"fam.png\" style=\"width:600px; height:100px/\"> \n",
    "<img src=\"kk.png\" style=\"width:600px; height:100px/\"> \n",
    "\n",
    "**Future work**:\n",
    "<br /> While EEG measures the electrical activity of the brain, fMRI measures the blood flow and oxygenation in the brain. By combining these two modalities, we can get a more complete picture of the brain activity and identify regions of the brain that may not be easily detected by either modality alone.\n",
    "\n",
    "As EEG has high temporal resolution but poor spatial resolution, while fMRI has high spatial resolution but poor temporal resolution. By combining these two modalities, we can obtain both high temporal and spatial resolution.\n",
    "<img src=\"fu.png\" style=\"width:600px; height:100px/\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987217ec",
   "metadata": {},
   "source": [
    "**Key Takeaways**:\n",
    "1. When we approach a research problem, there are often multiple ways to tackle it.\n",
    "2. In the case of classifying epilepsy from EEG data, we explored different approaches such as classification based on handcrafted features, 1D CNNs, 2D CNNs, convolutional autoencoders, denoising autoencoders, and transfer learning models.\n",
    "3. Each approach has its own strengths and weaknesses, and it is important to consider the trade-offs between them before choosing a particular method.\n",
    "4. Using handcrafted features allowed us to interpret the results and gain insights into which features are most relevant for classification.\n",
    "5. On the other hand, deep learning approaches like CNNs, autoencoders, and transfer learning models can automatically learn features from the data and improve the classification performance.\n",
    "6. Finally, the choice of approach depends on the specific problem at hand and the available resources, and it is important to consider and compare multiple approaches before making a final decision.\n",
    "\n",
    "**Deliverables**:\n",
    "* A GitHub repository containing the workflow and documentation of the project.\n",
    "* An oral presentation in the class.\n",
    "\n",
    "**References**:\n",
    "1. About Epilepsy | CDC. About Epilepsy | CDC, 30 Sept. 2020, www.cdc.gov/epilepsy/about/index.htm. \n",
    "2. Vagus Nerve Stimulation - Mayo Clinic. Vagus Nerve Stimulation - Mayo Clinic, 17 Nov. 2020.\n",
    "3. https://mikaelhaji.medium.com/a-technical-deep-dive-on-elon-musks-neuralink-in-40-mins-71e1100f54d4\n",
    "4. EEG Database From University of Bonn, Jun. 2013, [online] Available: http://www.epileptologiebonn.de.\n",
    "5. Shensa, Mark J. \"The discrete wavelet transform: wedding the a trous and Mallat algorithms.\" IEEE Transactions on signal processing 40.10 (1992): 2464-2482.\n",
    "6. Abdi, Hervé, and Lynne J. Williams. \"Principal component analysis.\" Wiley interdisciplinary reviews: computational statistics 2.4 (2010): 433-459.\n",
    "7. Yu, Xiang, Jian Wang, Qing-Qi Hong, Raja Teku, Shui-Hua Wang, and Yu-Dong Zhang. \"Transfer learning for medical images analyses: A survey.\" Neurocomputing 489 (2022): 230-254. \n",
    "8. Qu, Guiguo, and Qi Yuan. \"Epileptogenic region detection based on deep CNN with transfer learning.\" In 2019 IEEE 11th International Conference on Advanced Infocomm Technology (ICAIT), pp. 73-77. IEEE, 2019.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
